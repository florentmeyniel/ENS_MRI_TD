{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ENS Master: hands on MRI\n",
    "__Content creator:__ Florent Meyniel, NeuroSpin, CEA Paris-Saclay & Institut de NeuroModulation, Sainte Anne Hospital, Paris\n",
    "\n",
    "I would like to acknowledge my colleagues [Le Ster _et al._ (2019)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0225286) for sharing their data on the OpenNeuro platform ([here](https://openneuro.org/datasets/ds002606)). This notebook analyzes a sample participant from this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use a Python notebook?\n",
    "If you are running this notebook in Google colab, first make sure that you are connected to a computer. If \"Connected\" or \"RAM and disk\" appears in the top, right-hand side corner, you are fine! otherwise, click on \"Connect\".\n",
    "\n",
    "You can skip the remainder of this section if you already know about Python notebook (jupyter-notebook, google colab).\n",
    "\n",
    "The goal of today's session is *not* to learn how to program with Python. However, we will use Python to run some examples and do computations, so here is a quick introduction to Python notebook.\n",
    "\n",
    "A notebook mixes text, lines of code that can be executed, and results that are displayed.\n",
    "\n",
    "There are different ways to execute the code in a cell. All are equivalent:\n",
    "- put the cursor in the cell of code and press \"SHIFT\"+\"ENTER\".\n",
    "- or click on the \"play\" icon (the triangle) on the left-hand side of the cell.\n",
    "\n",
    "For example, the next line asks Python to compute \"1+1\". Execute the line of code to display the (expected) result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number in squared brackets indicates the order in which cells was executed. If you execute again the cell above, you will see that the number within the squared brackets increases. \n",
    "\n",
    "Now, you are going to type your own piece of code in the empty line below. Let's try 2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to insert your own new cell and enter your code there, click on the \"+\" button in the menu bar at the top of this page. Insert a new cell below and a new code, e.g. 2+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up the environment\n",
    "Do various imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do various imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Different subjects, different brains\n",
    "The study by Le Ster and colleagues, as most neuro-imaging studies, is performed at the level of a group of subjects in order to estimate the statistical significance of the results. \n",
    "\n",
    "In a new tab, open the [link to the data stored on OpenNeuro](https://openneuro.org/datasets/ds002606).\n",
    "\n",
    "**Q1-1: How many participants were included in the study?**\n",
    "\n",
    "We are going to explore the data set. Browse the data: open sub_03 / ses-01 / anat and open the anatomical image of this subject by clicking on the \"view\" icon (open it in a new tab). Or alternatively, click [here](https://openneuro.org/datasets/ds002606/versions/1.0.1/file-display/sub-03:ses-01:anat:sub-03_ses-01_T1w.nii.gz) (again, open this link in a new tab).\n",
    "\n",
    "**Q1-2: Knowing that this is an anatomical image, what kind of weighting was used? T1 or T2?**\n",
    "\n",
    "**Q1-3: What do you see in the anatomical image?**\n",
    "\n",
    "You can navigate in this image by moving the cursor.\n",
    "\n",
    "**Q1-4: Can you see the nose, eyes, ears of the participants? Why?**\n",
    "\n",
    "In another tab, display the anatomy of the [subject-04](https://openneuro.org/datasets/ds002606/versions/1.0.1/file-display/sub-04:ses-01:anat:sub-04_ses-01_T1w.nii.gz).\n",
    "\n",
    "**Q1-5: Compare the two anatomies. Do they look similar?**\n",
    "\n",
    "In order to compare quantitatively the anatomy of those two participants, we are going to measure the distance between two anatomical landmarks: the anterior and posterior commissures.\n",
    "\n",
    "**Presentation of the landmarks**\n",
    "\n",
    "Beyond this exercise, it is interesting to know about those landmarks, because the most widely used frames of reference for brain anatomy uses:\n",
    "- the anterior commissure as its origin.\n",
    "- the axis passing through the anterior and posterior commissures as the antero-posterior axis (labeled y). The plane that contains this axis and that is oriented so as to separate the left and right hemispheres is the sagital plane.\n",
    "- the axis orthogonal to the sagital plane corresponds to the left-right axis (labeled x), it is embedded in the axial plane\n",
    "- the axis orthogonoal to those two axes is the bottom-to-top axis (labeled z).\n",
    "This frame of reference is used by the [Talairach](https://en.wikipedia.org/wiki/Talairach_coordinates) and the Montreal Neurological Institute [(MNI)](http://www.bic.mni.mcgill.ca/~louis/stx_history.html) coordinate systems.\n",
    "\n",
    "Try to locate the anterior and posterior commissures using the online viewer and [subject-03](https://openneuro.org/datasets/ds002606/versions/1.0.1/file-display/sub-03:ses-01:anat:sub-03_ses-01_T1w.nii.gz). In order to locate those two landmarks, use the description and pictures provided by this [guide](https://neuroimage.usc.edu/brainstorm/CoordinateSystems) (see the section \"Talairach coordinates\").\n",
    "\n",
    "**Measure the distance**\n",
    "\n",
    "Unfortunately, the image viewer on openneuro.org does not displays the coordinates of the crosshairs, so we cannot measure the distance between those two landmarks!\n",
    "To get the coordinates, we will use a browerser-based: [bioimagesuiteweb](https://bioimagesuiteweb.github.io/webapp/viewer.html#)*MRICron*. \n",
    "* How to use bioimagesuitedweb. \n",
    "    + Download the anatomical images of our two sample participants from the openneuro website (or use [subject-03](https://openneuro.org/crn/datasets/ds002606/files/sub-03:ses-01:anat:sub-03_ses-01_T1w.nii.gz) and [subject-04](https://openneuro.org/crn/datasets/ds002606/files/sub-04:ses-01:anat:sub-04_ses-01_T1w.nii.gz) for direct download).\n",
    "    + Do *file>Load Image*, and select the file of subject 03 (you will do subject 04 after)\n",
    "    + The native range of the gray scale is inadequate to clearly see the images. You can ajust the range in Image Color Mapping (side bar on the right). The range [0, 250] works better\n",
    "    + Look for the anterior and posterior commissures and mark down their (voxel) corrdinates (X, Y, Z that appear on bottom left). Load the anatomical image of the other subject and repeat the same steps.\n",
    "* You can work in pairs\n",
    "\n",
    "To compute the distance between two landmarks A and B, for each subject, we use the following formula:\n",
    "$\\sqrt{(A_x - B_x)^2 + (A_y - B_y)^2 + (A_z - B_z)^2 }$ which is implemented in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject #3, AC to PC= 0.00  voxels\n",
      "Subject #4, AC to PC= 0.00  voxels\n"
     ]
    }
   ],
   "source": [
    "def distance(A, B):\n",
    "    return np.sqrt(np.sum([(a-b)**2 for a, b in zip(A, B)]))\n",
    "\n",
    "# Subject #3 (replace AC and PC with the values that you have marked down)\n",
    "AC = [0, 0, 0]\n",
    "PC = [0, 0, 0]\n",
    "print('Subject #3, AC to PC=', f\"{distance(AC, PC):.2f}\", ' voxels')\n",
    "\n",
    "# Subject #4 (replace AC and PC with the values that you have marked down)\n",
    "AC = [0, 0, 0]\n",
    "PC = [0, 0, 0]\n",
    "print('Subject #4, AC to PC=', f\"{distance(AC, PC):.2f}\", ' voxels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1-6: Which subject has the largest brain among those two participants?**\n",
    "\n",
    "**Q1-7: What problems do you foresee for group-level analysis?**\n",
    "\n",
    "In order to ensure a voxel-to-voxel correspondence across participants, we normalize the anatomy. The simplest way of normalizing anatomy is to move (translation, rotation) and stretch (along the three possible axes) the brain of each subject so as to best match the anatomy of another subject that serves as reference. \n",
    "\n",
    "In practice, the reference anatomy is not from a subject in our group, but is a reference anatomy used by everybody in the research community. Having a common reference anatomy across studies ensures that the brain coordinates are the same across studies. The Montreal Neurological Institute has created such a reference anatomy which is widely used nowadays. \n",
    "\n",
    "The normalization is estimated based on the anatomical image of the subject, and then applied to the functional images, such that the coordinate system of the functional images becomes normalized too.\n",
    "\n",
    "If you have completed this section and need to wait before doing the group recap, or if you want to learn more, you can visit:\n",
    "- this online version of the [text-book](https://www.fil.ion.ucl.ac.uk/spm/doc/books/hbf2/), especially section 2-3\n",
    "- those [slides](https://www.fil.ion.ucl.ac.uk/spm/course/slides19-may/), especially 01_fMRI_preprocessing.pptx\n",
    "\n",
    "that are provided by the SPM team at University College London."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing of data\n",
    "\n",
    "Normalization is one of the many steps of a standard pre-preprocessing pipeline.\n",
    "In this TD, we are going to use data that have been pre-processed following those steps:\n",
    "- slice timing correction: timeseries in each slice are corrected so as to have the same timing (i.e. as if they had been sampled at the same time). \n",
    "- realignment: consecutive volumes are realigned to correct for volume-to-volume movement of subjects\n",
    "- distortion of corrections induced by local field inhomogeneity\n",
    "- coregistration of the functional and anatomical images\n",
    "- normalisation of the anatomical image to a standard template. The same deformation is applied to functional images.\n",
    "- spatial smoothing of the data.\n",
    "\n",
    "**Q1-8: Comment each step: why do we do that?**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
